<!DOCTYPE html>
<html><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="E検定チャレンジ用">
    
    <link rel="shortcut icon" href="https://example.com/favicon.ico">
    
    <link rel="stylesheet" href="/css/style.min.css">

    <title>応用数学レポート</title>
</head>
<body><header id="banner">
    <h2><a href="https://example.com">ラビットチャレンジレポート提出用サイト</a></h2>
    <nav>
        <ul>
            <li>
                <a href="/" title="posts">posts</a>
            </li><li>
                <a href="/about/" title="about">about</a>
            </li>
        </ul>
    </nav>
</header>
<main id="content">
<article>
    <header id="post-header">
        <h1>応用数学レポート</h1>
            <div>
                <time>June 7, 2021</time>
                </div>
    </header><h1 id="第1章線形代数">第1章　線形代数</h1>
<p>スカラーとベクトルの違いや行列の基本計算方法（四則演算）の習得後、行列の固有値・固有ベクトルの算出方法について習得。
また、正方行列以外の行列に対する固有値・固有ベクトルの算出方法として、特異値・特異ベクトルの算出方法について習得。
最後に、アインシュタインの画像を用いて、特異値分解が実際に利用されている場面について紹介があり、特異値分解が実際の画像処理の場面でどのように活用されているかを習得する事ができた。</p>
<h1 id="第2章確率統計">第2章　確率・統計</h1>
<p>基本的な集合の概念や確率の基本的な求め方について習得した後、条件付き確率について習得した。
「洗濯物を干している日に雨が降る確率」と「洗濯物を干しているかつ雨が降る確率」が異なるという演習の問題を通じて、条件付き確率と独立な事象の同時確率の違いについて理解を深めた。
ベイズの定理（講義内ではベイズ則）については、結果から原因を推定する際に利用されていると認識している。</p>
<p>また、標本分散と不偏分散の違いの部分での説明は、講師が口頭にてわかりやすく説明。
不偏分散と標本分散では、分母がn-1とnで異なるが、これは分散が標本平均と各標本との差分の二乗を合計しているからで、標本平均を導出する際にすでに自由度が1減少していることから、不偏分散では分母が標本数のnではなくn-1が採用されたと理解した。最後に、様々な分布の説明では、ベルヌーイ分布・二項分布・正規分布などの具体的な数式について習得した。</p>
<h1 id="第3章情報理論">第3章　情報理論</h1>
<p>情報理論についてはこれまであまり触れた事がない分野だったため、新鮮だった。
自己情報量は、元の情報量からどれくらい増加しているかを比率で考え、それを数式化する際には log をとるということを習得。
（logの底が2の場合は単位がbit、logの底がeの場合は単位がnat）
また、シャノンエントロピーは自己情報量の期待値という定義について習得し、シャノンエントロピーの定性的な意味について理解した。
カルバック・ライブラー・ダイバージェンスは、同じ事象・確率変数における異なる確率分布の違いについて、定量的に表したものと理解。
カルバック・ライブラー・ダイバージェンスの中で、古い確率分布で見た自己情報量を新しい確率分布で平均した項は、交差エントロピーということを理解した。</p>
</article>

        </main><footer id="footer">
    Copyright © 2021 Yuki Ono
</footer>
</body>
</html>
