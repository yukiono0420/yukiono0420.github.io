---
title: "機械学習レポート"
date: 2021-06-12T01:18:19+09:00
draft: false
mathjax: true
---
# 線形回帰モデル（単回帰モデル）
## 講義内容サマリ
### 回帰問題
回帰モデルではある入力値（離散あるいは連続）から出力値（連続）を予測する問題であり、線形関数（直線）で予測するものを線形回帰（単回帰）という。
* 回帰で扱うデータ
  * 入力値（各要素を説明変数または特徴量と呼ぶ）
     * m次元ベクトル（m=1の場合はスカラー） 
  * 出力値（目的変数）
     * スカラー値（目的変数）

**入力値（説明変数）**
`$$
\begin{eqnarray*}
\boldsymbol{x} &=& (x_1, x_2, \cdots, x_m)^{T} \\
\end{eqnarray*}
$$`

**出力値（目的変数）**
`$$
\begin{eqnarray*}
y \in \mathbb{R}^m \\
\end{eqnarray*}
$$`

### 線形回帰モデル
線形回帰モデルとは、機械学習モデルの一つであり、教師あり学習の回帰手法である。
入力値に対して$m$次元パラメータの線型結合を出力するモデルである。
パラメータとは、モデルに含まれる推定すべき未知のパラメータであり、特徴量が予測値に対してどのように影響を与えるかを決定する重み値の集合である。
線形回帰モデルでは、この未知のパラメータに対して、最小二乗法により推定する。

**パラメータ**
`$$
\begin{eqnarray*}
\boldsymbol{w} &=& (w_1, w_2, \cdots, w_m)^{T} \in \mathbb{R}^m \\
\end{eqnarray*}
$$`

**線型結合**
`$$
\begin{eqnarray*}
 \hat{y} = \boldsymbol{w}^T \boldsymbol{x} + w_0 = \sum^{m}_{j=1} w_j x_j + w_0 \\
\end{eqnarray*}
$$`

### データの分割とモデルの汎化性能測定
教師用データについて、学習用データと検証用データにそれぞれ分割する。モデルの汎化性能（Generalization）を測定するためで、データへの当てはまりの良さではなく、未知のインプットデータに対しての精度の高さを測定する。
* 学習用データ：機械学習モデルの学習に利用するデータ
* 検証用データ：学習済みモデルの制度を検証するためのデータ

### 線形回帰モデルパラメータの推定
モデルパラメータの推定は、以下の平均二乗誤差MSE$_{train}$（残渣平方和：データとモデル出力の二乗誤差の和）を最小化するパラメータを探索する。
`$$
\begin{eqnarray*}
 \rm{MSE}_{train} = \frac{1}{n_{train}} \sum^{n_{train}}_{i=1} (\hat{y}^{(train)}_i - y^{(train)}_i)^2 \\ 
\end{eqnarray*}
$$`

MSEを最小とするような$w$を求めるため、以下の方程式を解く。
\begin{eqnarray*}
 \frac{\partial}{\partial w}\rm{MST_{train}} = 0 \\
\end{eqnarray*}
左辺について行列変形を実施する。
`
\begin{eqnarray*}
 \frac{\partial}{\partial w}\rm{MST_{train}} &=&  \frac{\partial}{\partial w} \left(\frac{1}{n_{\rm{train}}} \sum^{n_{\rm{(train)}}}_{i=1} \left(\hat{y}^{\rm{(train)}}_i - y^{\rm{(train)}}_i\right)^2 \right) \\
&=& \frac{\partial}{\partial \boldsymbol{w}} \left( \left(X^{n_{\rm{(train)}}} \boldsymbol{w} - \boldsymbol{y}^{(\rm{train})} \right)^T \left(X^{n_{\rm{(train)}}} \boldsymbol{w} - \boldsymbol{y}^{(\rm{(train)})} \right) \right) \\
&=& 0  \\
\end{eqnarray*}
`
これを解くと以下の回帰係数の式が得られる。
* 回帰係数
\begin{eqnarray*}
 \boldsymbol{\hat{w}} &=& \left({X^{\rm{(train)}}}^{T} X^{\rm{(train)}}\right)^{-1} {X^{\rm{(train)}}}^{T} \boldsymbol{y}^{\rm{(train)}} \\
\end{eqnarray*}

* 予測値
\begin{eqnarray*}
 \boldsymbol{\hat{y}} &=& X\left({X^{\rm{(train)}}}^{T} X^{\rm{(train)}}\right)^{-1} {X^{\rm{(train)}}}^{T} \boldsymbol{y}^{\rm{(train)}} \\
\end{eqnarray*}
